{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary Image classification - cat or dog using rgb image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- imported Sequential from keras.models, to initialise our neural network model as a sequential network. There are two basic ways of initialising a neural network, either by a sequence of layers or as a graph.\n",
    "- imported Conv2D from keras.layers, working on images => 2 Dimensional arrays, Convolution 3-D is for videos, where the third dimension will be time.\n",
    "- imported MaxPooling2D from keras.layers, there exist different types of pooling operations like Min Pooling, Mean Pooling, etc. Here in MaxPooling we need the maximum value pixel from the respective region of interest.\n",
    "- imported Flatten from keras.layers, Flattening is the process of converting all the resultant 2 dimensional arrays into a single long continuous linear vector.\n",
    "- imported Dense from keras.layers, which is used to perform the full connection of the neural network.\n",
    "- imported ImageDataGenerator from keras.preprocessing.image, which is used for image preprocessing like flipping, rotating, blurring, rescaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Conv2D\n",
    "\n",
    "from keras.layers import MaxPooling2D\n",
    "\n",
    "from keras.layers import Flatten\n",
    "\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create an object of the sequential class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequential convolution layer \n",
    "- 32 : no.of filters\n",
    "- (3x3) : shape of each filter\n",
    "- (64, 64, 3): input shape 64x64 resolution and the type of image 3 channel RGB\n",
    "- activation function : relu, rectifier function, allows only positive values to pass through it. The negative values are mapped to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "perform pooling operation on the resultant feature maps we get after the convolution operation is done on an image.\n",
    "Here we are trying to reduce the total number of nodes for the upcoming layers.\n",
    "We take a 2x2 matrix we’ll have minimum pixel loss and get a precise region where the feature are located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking the 2-D array, i.e pooled image pixels and converting them to a one dimensional single vector through Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fully-connected layers:\n",
    "As this layer will be present between the input layer and output layer, we can refer to it a hidden layer.\n",
    "- Dense : function to add a fully connected layer\n",
    "- units : the number of nodes that should be present in this hidden layer, value will be always between the number of input nodes and the output nodes. optimal number of nodes can be achieved only through experimental tries. use a power of 2.\n",
    "- activation function : rectifier function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.add(Dense(units = 128, activation = 'relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "output layer:\n",
    "should contain only one node, as it is binary classification. This single node will give us a binary output of either a Cat or Dog.\n",
    "final layer contains only one node, and we will be using a sigmoid activation function for the final layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "completed building our CNN model, it’s time to compile it\n",
    "- Optimizer parameter : to choose the stochastic gradient descent algorithm.\n",
    "- Loss parameter : to choose the loss function.\n",
    "- metrics parameter : to choose the performance metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image preprocessing so that it doesnt overfit.\n",
    "- rescaling,horizontal flip https://keras.io/preprocessing/image/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8005 images belonging to 2 classes.\n",
      "Found 2023 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "shear_range = 0.2,\n",
    "zoom_range = 0.2,\n",
    "horizontal_flip = True)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "training_set = train_datagen.flow_from_directory('dataset/training_set_cd/',\n",
    "target_size = (64, 64),\n",
    "batch_size = 32,\n",
    "class_mode = 'binary')\n",
    "test_set = test_datagen.flow_from_directory('dataset/test_set_cd/',\n",
    "target_size = (64, 64),\n",
    "batch_size = 32,\n",
    "class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets fit the data to our model !\n",
    "- steps_per_epoch : holds the number of training images, i.e the number of images the training_set folder contains.\n",
    "- epochs : A single epoch is a single step, a neural network is trained on every training samples only in one pass we say that one epoch is finished. So training process should consist more than one epochs.In this case we have defined 2 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      " 726/8000 [=>............................] - ETA: 56:23 - loss: 0.6093 - acc: 0.6713"
     ]
    }
   ],
   "source": [
    "classifier.fit_generator(training_set,\n",
    "steps_per_epoch = 8000,\n",
    "epochs = 2,\n",
    "validation_data = test_set,\n",
    "validation_steps = 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making new predictions from our trained model :\n",
    " -  we have the test image, we will prepare the image to be sent into the model by converting its resolution to 64x64 as the model only excepts that resolution. \n",
    " - we are using predict() method on our classifier object to get the prediction. As the prediction will be in a binary form, we will be receiving either a 1 or 0, which will represent a dog or a cat respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('dataset/single_prediction/cat_or_dog_1.jpg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = classifier.predict(test_image)\n",
    "training_set.class_indices\n",
    "if result[0][0] == 1:\n",
    "prediction = 'dog'\n",
    "else:\n",
    "prediction = 'cat'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
